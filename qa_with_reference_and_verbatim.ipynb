{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf47de76",
   "metadata": {},
   "source": [
    "# QA with reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad2d0bd",
   "metadata": {},
   "source": [
    "We believe that hallucinations pose a major problem in the adoption of LLMs (Language Model Models). It is imperative to provide a simple and quick solution that allows the user to verify the coherence of the answers to the questions they are asked.\n",
    "\n",
    "The conventional approach is to provide a list of URLs of the documents that helped in answering (see qa_with_source). However, this approach is unsatisfactory in several scenarios:\n",
    "\n",
    "1. The question is asked about a PDF of over 100 pages. Each fragment comes from the same document, but from where?\n",
    "2. Some documents do not have URLs (data retrieved from a database or other loaders).\n",
    "\n",
    "It appears essential to have a means of retrieving all references to the actual data sources used by the model to answer the question. \n",
    "\n",
    "This includes:\n",
    "- The precise list of documents used for the answer (the `Documents`, along with their metadata that may contain page numbers, slide numbers, or any other information allowing the retrieval of the fragment in the original document).\n",
    "- The excerpts of text used for the answer in each fragment. Even if a fragment is used, the LLM only utilizes a small portion to generate the answer. Access to these verbatim excerpts helps to quickly ascertain the validity of the answer.\n",
    "\n",
    "We propose a new pipeline: `qa_with_reference` for this purpose. It is a Question/Answer type pipeline that returns the list of documents used, and in the metadata, the list of verbatim excerpts exploited to produce the answer.\n",
    "\n",
    "*At this time, only the `map_reduce` chain type car extract the verbatim excerpts.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017713e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install 'langchain-qa_with_references[openai]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5cfcfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "from langchain.schema import Document\n",
    "llm = OpenAI(\n",
    "            temperature=0,\n",
    "            max_tokens=1000,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91adeece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To answer \"He eats apples, pears and carrots.\", the LLM use:\n",
      "Document 0\n",
      "- \"he eats apples\"\n",
      "- \"he eats pears.\"\n",
      "Document 1\n",
      "- \"he eats carrots.\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_qa_with_references.chains import QAWithReferencesAndVerbatimsChain\n",
    "chain_type=\"map_reduce\"  # Only map_reduce can extract the verbatim.\n",
    "qa_chain = QAWithReferencesAndVerbatimsChain.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=chain_type,\n",
    "    )\n",
    "\n",
    "question = \"what does it eat?\"\n",
    "bodies = [\"he eats apples and plays football.\"\n",
    "          \"My name is Philippe.\"\n",
    "          \n",
    "          \"he eats pears.\",\n",
    "          \n",
    "          \"he eats carrots. I like football.\",\n",
    "          \"The Earth is round.\"\n",
    "]\n",
    "docs=[Document(page_content=body,metadata={\"id\":i}) for i,body in enumerate(bodies)]\n",
    "\n",
    "answer = qa_chain(\n",
    "        inputs={\n",
    "            \"docs\": docs,\n",
    "            \"question\": question,\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "print(f'To answer \"{answer[\"answer\"]}\", the LLM use:')\n",
    "for doc in answer[\"source_documents\"]:\n",
    "    print(f\"Document {doc.metadata['id']}\")\n",
    "    for verbatim in doc.metadata.get(\"verbatims\",[]):\n",
    "        print(f'- \"{verbatim}\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9796e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install chroma wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9edf625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.retrievers import WikipediaRetriever\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "wikipedia_retriever = WikipediaRetriever()\n",
    "vectorstore = Chroma(\n",
    "    embedding_function=OpenAIEmbeddings(),\n",
    "    persist_directory=\"/tmp/chroma_db_oai\",\n",
    ")\n",
    "docs = wikipedia_retriever.get_relevant_documents(question)\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "split_docs = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, chunk_overlap=10\n",
    ").split_documents(docs)\n",
    "\n",
    "vectorstore.add_documents(split_docs)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "question = \"what can you say about ukraine?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "835290d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the question \"what can you say about ukraine?\", to answer \"Ukraine's ethnocentrism, Ukraine's existence, Ukraine should be dismantled, Ukraine cannot be allowed to exist, the brutal censorship of the Ukrainian culture, large-scale de-ukrainization of Ukrainians, Ukraine's ethnocentrism is an artificial perversion, Ukraine's existence is impossible as a nation-state, the word 'Ukraine' itself cannot be allowed to exist, Ukraine should be dismantled and replaced with several states, the Ukrainian people's right to self-determination would not be infringed upon\", the LLM use:\n",
      "Source https://en.wikipedia.org/wiki/Russo-Ukrainian_War\n",
      "-  \"Ukraine.\"\n",
      "Source https://en.wikipedia.org/wiki/What_Russia_Should_Do_with_Ukraine\n",
      "-  \"Ukraine's ethnocentrism\"\n",
      "-  \"Ukraine's existence\"\n",
      "-  \"Ukraine should be dismantled\"\n",
      "Source https://en.wikipedia.org/wiki/What_Russia_Should_Do_with_Ukraine\n",
      "-  \"brutal censorship\" of the Ukrainian culture\"\n",
      "-  \"large-scale \"de-ukrainization\" of Ukrainians\"\n",
      "-  \"Ukraine's ethnocentrism is an artificial perversion\"\n",
      "-  \"Ukraine's existence is \"impossible\" as a nation-state\"\n",
      "-  \"the word \"Ukraine\" itself cannot be allowed to exist.\"\n",
      "-  \"Ukraine should be dismantled and replaced with several states\"\n",
      "Source https://en.wikipedia.org/wiki/What_Russia_Should_Do_with_Ukraine\n",
      "-  \"the Ukrainian people's right to self-determination would not be infringed upon.\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_qa_with_references.chains import RetrievalQAWithReferencesAndVerbatimsChain\n",
    "from typing import Literal\n",
    "chain_type:Literal[\"stuff\",\"map_reduce\",\"map_rerank\",\"refine\"]=\"map_reduce\"\n",
    "\n",
    "qa_chain = RetrievalQAWithReferencesAndVerbatimsChain.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=chain_type,\n",
    "    retriever=retriever,\n",
    "    reduce_k_below_max_tokens=True,\n",
    ")\n",
    "answer = qa_chain(\n",
    "    inputs={\n",
    "        \"question\": question,\n",
    "    }\n",
    ")\n",
    "print(f'For the question \"{question}\", to answer \"{answer[\"answer\"]}\", the LLM use:')\n",
    "for doc in answer[\"source_documents\"]:\n",
    "    print(f\"Source {doc.metadata['source']}\")\n",
    "    for verbatim in doc.metadata.get(\"verbatims\", []):\n",
    "        print(f'-  \"{verbatim}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00154995",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qa_with_ref",
   "language": "python",
   "name": "qa_with_ref"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
