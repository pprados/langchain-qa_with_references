{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "144cf713-0c9c-40ce-95cf-a969a2ed93ce",
   "metadata": {},
   "source": [
    "# QA with reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673a6b73-0155-4001-bba2-0454d5a0386a",
   "metadata": {},
   "source": [
    "We believe that hallucinations pose a major problem in the adoption of LLMs (Language Model Models). It is imperative to provide a simple and quick solution that allows the user to verify the coherence of the answers to the questions they are asked.\n",
    "\n",
    "The conventional approach is to provide a list of URLs of the documents that helped in answering (see qa_with_source). However, this approach is unsatisfactory in several scenarios:\n",
    "\n",
    "1. The question is asked about a PDF of over 100 pages. Each fragment comes from the same document, but from where?\n",
    "2. Some documents do not have URLs (data retrieved from a database or other loaders).\n",
    "\n",
    "It appears essential to have a means of retrieving all references to the actual data sources used by the model to answer the question. \n",
    "\n",
    "This includes:\n",
    "- The precise list of documents used for the answer (the `Documents`, along with their metadata that may contain page numbers, slide numbers, or any other information allowing the retrieval of the fragment in the original document).\n",
    "- The excerpts of text used for the answer in each fragment. Even if a fragment is used, the LLM only utilizes a small portion to generate the answer. Access to these verbatim excerpts helps to quickly ascertain the validity of the answer.\n",
    "\n",
    "We propose a new pipeline: `qa_with_reference` for this purpose. It is a Question/Answer type pipeline that returns the list of documents used, and in the metadata, the list of verbatim excerpts exploited to produce the answer.\n",
    "\n",
    "*At this time, only the `map_reduce` chain type car extract the verbatim excerpts.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50b301ae-b643-4b3c-9410-24169c7cfb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-qa_with_references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19582d4d-7c45-47db-8d67-36d648ba6750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "from langchain.schema import Document\n",
    "llm = OpenAI(\n",
    "            temperature=0,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1de55e85-b1e4-4aaf-b9ae-16a2f46c7d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To answer \"\", the LLM use:\n",
      "Document 0\n",
      "- \"eats apples\"\n",
      "- \"eats pears.\"\n",
      "Document 1\n",
      "- \"he eats carrots.\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_qa_with_references.chains import QAWithReferencesAndVerbatimsChain\n",
    "chain_type=\"map_reduce\"  # Only map_reduce can extract the verbatim.\n",
    "qa_chain = QAWithReferencesAndVerbatimsChain.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=chain_type,\n",
    "    )\n",
    "\n",
    "question = \"what does it eat?\"\n",
    "bodies = [\"he eats apples and plays football.\"\n",
    "          \"My name is Philippe.\"\n",
    "          \n",
    "          \"he eats pears.\",\n",
    "          \n",
    "          \"he eats carrots. I like football.\",\n",
    "          \"The Earth is round.\"\n",
    "]\n",
    "docs=[Document(page_content=body,metadata={\"id\":i}) for i,body in enumerate(bodies)]\n",
    "\n",
    "answer = qa_chain(\n",
    "        inputs={\n",
    "            \"docs\": docs,\n",
    "            \"question\": question,\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "print(f'To answer \"{answer[\"answer\"]}\", the LLM use:')\n",
    "for doc in answer[\"source_documents\"]:\n",
    "    print(f\"Document {doc.metadata['id']}\")\n",
    "    for verbatim in doc.metadata.get(\"verbatims\",[]):\n",
    "        print(f'- \"{verbatim}\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "157a1870-6dc4-429e-b4a2-9f2a9de6f913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install faiss-cpu sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c42b257-6ca3-429b-ace9-2b459df6ff16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "loader = DirectoryLoader('./', glob=\"**/*.md\", loader_cls=TextLoader)\n",
    "docs = loader.load()\n",
    "\n",
    "# Text Splitters\n",
    "from langchain.text_splitter import MarkdownTextSplitter\n",
    "markdown_splitter = MarkdownTextSplitter(chunk_size=2000, chunk_overlap=100, length_function=len)\n",
    "md_docs = markdown_splitter.split_documents(docs)\n",
    "\n",
    "# Embeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings  # create custom embeddings class that just calls API\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Vector stores (pip install faiss or pip install faiss-cpu)\n",
    "from langchain.vectorstores import FAISS\n",
    "db = FAISS.from_documents(md_docs, embeddings)\n",
    "\n",
    "# Retrievers\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 4})\n",
    "question = \"How do I use OpenAI?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "046e8904-74b9-4739-bd88-dd1a9c0ff4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the question \"How do I use OpenAI?\", to answer \"\", the LLM use:\n",
      "Source ./_dist/docs_skeleton/docs/integrations/chat/openai.md\n",
      "-  \"This notebook covers how to get started with OpenAI chat models.\"\n",
      "Source ./_dist/docs_skeleton/docs/modules/agents/how_to/use_toolkits_with_openai_functions.md\n",
      "-  \"This notebook shows how to use the OpenAI functions agent with arbitrary toolkits.\"\n",
      "Source ./_dist/docs_skeleton/docs/guides/adapters/openai.md\n",
      "-  \"At the moment this only deals with output and does not return other information (token counts, stop reasons, etc\"\n",
      "-  \"LangChain's integrations with many model providers make this easy to do so.\"\n",
      "-  \"While LangChain has it's own message and model APIs, we've also made it as easy as possible to explore other models by exposing an adapter to adapt LangChain models to the OpenAI api.\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_qa_with_references.chains import RetrievalQAWithReferencesAndVerbatimsChain\n",
    "from typing import Literal\n",
    "chain_type:Literal[\"stuff\",\"map_reduce\",\"map_rerank\",\"refine\"]=\"map_reduce\"\n",
    "\n",
    "qa_chain = RetrievalQAWithReferencesAndVerbatimsChain.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=chain_type,\n",
    "    retriever=retriever,\n",
    "    reduce_k_below_max_tokens=True,\n",
    ")\n",
    "answer = qa_chain(\n",
    "    inputs={\n",
    "        \"question\": question,\n",
    "    }\n",
    ")\n",
    "print(f'For the question \"{question}\", to answer \"{answer[\"answer\"]}\", the LLM use:')\n",
    "for doc in answer[\"source_documents\"]:\n",
    "    print(f\"Source {doc.metadata['source']}\")\n",
    "    for verbatim in doc.metadata.get(\"verbatims\", []):\n",
    "        print(f'-  \"{verbatim}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563e5cc2-e02d-4c25-aa00-3d1440e33c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "propaleur",
   "language": "python",
   "name": "propaleur"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
