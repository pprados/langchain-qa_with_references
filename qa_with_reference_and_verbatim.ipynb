{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "144cf713-0c9c-40ce-95cf-a969a2ed93ce",
   "metadata": {},
   "source": [
    "# QA with reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673a6b73-0155-4001-bba2-0454d5a0386a",
   "metadata": {},
   "source": [
    "We believe that hallucinations pose a major problem in the adoption of LLMs (Language Model Models). It is imperative to provide a simple and quick solution that allows the user to verify the coherence of the answers to the questions they are asked.\n",
    "\n",
    "The conventional approach is to provide a list of URLs of the documents that helped in answering (see qa_with_source). However, this approach is unsatisfactory in several scenarios:\n",
    "\n",
    "1. The question is asked about a PDF of over 100 pages. Each fragment comes from the same document, but from where?\n",
    "2. Some documents do not have URLs (data retrieved from a database or other loaders).\n",
    "\n",
    "It appears essential to have a means of retrieving all references to the actual data sources used by the model to answer the question. \n",
    "\n",
    "This includes:\n",
    "- The precise list of documents used for the answer (the `Documents`, along with their metadata that may contain page numbers, slide numbers, or any other information allowing the retrieval of the fragment in the original document).\n",
    "- The excerpts of text used for the answer in each fragment. Even if a fragment is used, the LLM only utilizes a small portion to generate the answer. Access to these verbatim excerpts helps to quickly ascertain the validity of the answer.\n",
    "\n",
    "We propose a new pipeline: `qa_with_reference` for this purpose. It is a Question/Answer type pipeline that returns the list of documents used, and in the metadata, the list of verbatim excerpts exploited to produce the answer.\n",
    "\n",
    "*At this time, only the `map_reduce` chain type car extract the verbatim excerpts.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50b301ae-b643-4b3c-9410-24169c7cfb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/pprados/workspace.bda/langchain-qa_with_references\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[33mWARNING: langchain-qa-with-references 0.0.0 does not provide the extra 'openai'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[?25hBuilding wheels for collected packages: langchain-qa-with-references\n",
      "  Building editable for langchain-qa-with-references (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langchain-qa-with-references: filename=langchain_qa_with_references-0.0.0-0.editable-py3-none-any.whl size=2792 sha256=3e27f1395366a6b6050e75608c4ff3e1343f517db2520618bbe7ca16b554e65f\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-baty_drg/wheels/51/a3/b9/7d0c81c8139d5e581d08941bf2abdf25d0661d966cabc6ae78\n",
      "Successfully built langchain-qa-with-references\n",
      "Installing collected packages: langchain-qa-with-references\n",
      "  Attempting uninstall: langchain-qa-with-references\n",
      "    Found existing installation: langchain-qa-with-references 0.0.0\n",
      "    Uninstalling langchain-qa-with-references-0.0.0:\n",
      "      Successfully uninstalled langchain-qa-with-references-0.0.0\n",
      "Successfully installed langchain-qa-with-references-0.0.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install 'langchain-qa_with_references[openai]'\n",
    "!pip install -e '.[openai]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19582d4d-7c45-47db-8d67-36d648ba6750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "from langchain.schema import Document\n",
    "llm = OpenAI(\n",
    "            temperature=0,\n",
    "            max_tokens=2000,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1de55e85-b1e4-4aaf-b9ae-16a2f46c7d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To answer \"He eats apples, pears and carrots.\", the LLM use:\n",
      "Document 0\n",
      "- \"he eats apples\"\n",
      "- \"he eats pears.\"\n",
      "Document 1\n",
      "- \"he eats carrots.\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_qa_with_references.chains import QAWithReferencesAndVerbatimsChain\n",
    "chain_type=\"map_reduce\"  # Only map_reduce can extract the verbatim.\n",
    "qa_chain = QAWithReferencesAndVerbatimsChain.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=chain_type,\n",
    "    )\n",
    "\n",
    "question = \"what does it eat?\"\n",
    "bodies = [\"he eats apples and plays football.\"\n",
    "          \"My name is Philippe.\"\n",
    "          \n",
    "          \"he eats pears.\",\n",
    "          \n",
    "          \"he eats carrots. I like football.\",\n",
    "          \"The Earth is round.\"\n",
    "]\n",
    "docs=[Document(page_content=body,metadata={\"id\":i}) for i,body in enumerate(bodies)]\n",
    "\n",
    "answer = qa_chain(\n",
    "        inputs={\n",
    "            \"docs\": docs,\n",
    "            \"question\": question,\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "print(f'To answer \"{answer[\"answer\"]}\", the LLM use:')\n",
    "for doc in answer[\"source_documents\"]:\n",
    "    print(f\"Document {doc.metadata['id']}\")\n",
    "    for verbatim in doc.metadata.get(\"verbatims\",[]):\n",
    "        print(f'- \"{verbatim}\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "157a1870-6dc4-429e-b4a2-9f2a9de6f913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chroma\n",
      "  Downloading Chroma-0.2.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: chroma\n",
      "  Building wheel for chroma (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for chroma: filename=Chroma-0.2.0-py3-none-any.whl size=7097 sha256=cdbd8c3b8acda0eaaf4de688c8edc12552471bf9a83f98c595e9891cd328cbc8\n",
      "  Stored in directory: /home/pprados/.cache/pip/wheels/58/74/75/a6ab7999ae473ecbe819bc5cae9ccb902429dd6c60795f5112\n",
      "Successfully built chroma\n",
      "Installing collected packages: chroma\n",
      "Successfully installed chroma-0.2.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c42b257-6ca3-429b-ace9-2b459df6ff16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "loader = DirectoryLoader('./', glob=\"**/*.md\", loader_cls=TextLoader)\n",
    "docs = loader.load()\n",
    "\n",
    "# Text Splitters\n",
    "from langchain.text_splitter import MarkdownTextSplitter\n",
    "markdown_splitter = MarkdownTextSplitter(chunk_size=2000, chunk_overlap=100, length_function=len)\n",
    "md_docs = markdown_splitter.split_documents(docs)\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "db = Chroma.from_documents(md_docs, embeddings)\n",
    "\n",
    "# Retrievers\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 4})\n",
    "question = \"How do I verify the coherence of the answers?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "673aabff-b911-40c1-a481-496939d2c13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"We believe that **hallucinations** pose a major problem in the adoption of LLMs (Language Model Models). \\nIt is imperative to provide a simple and quick solution that allows the user to verify the coherence of the answers \\nto the questions they are asked.\\n\\nThe conventional approach is to provide a list of URLs of the documents that helped in answering (see qa_with_source). \\nHowever, this approach is unsatisfactory in several scenarios:\\n1. The question is asked about a PDF of over 100 pages. Each fragment comes from the same document, but from where?\\n2. Some documents do not have URLs (data retrieved from a database or other *loaders*).\\n\\nIt appears essential to have a means of retrieving all references to the actual data sources used by the model to answer the question. \\n\\nThis includes:\\n- The precise list of documents used for the answer (the `Documents`, along with their metadata that may contain page numbers, \\nslide numbers, or any other information allowing the retrieval of the fragment in the original document).\\n- The excerpts of text used for the answer in each fragment. Even if a fragment is used, the LLM only utilizes a \\nsmall portion to generate the answer. Access to these verbatim excerpts helps to quickly ascertain the validity of the answer.\\n\\nWe propose a two pipelines: `qa_with_reference` and `qa_with_reference_and_verbatims` for this purpose. \\nIt is a Question/Answer type pipeline that returns the list of documents used, and in the metadata, the list of verbatim \\nexcerpts exploited to produce the answer.\\n\\nIf the verbatim is not really from the original document, it's removed.\\n# Install\\n```\\npip install langchain-qa_with_reference\\n```\\n\\n# Sample  notebook\\n\\nSee [here](qa_with_reference.ipynb)\\n\\n# langchain Pull-request\\nThis is a temporary project while I wait for my langchain \\n[pull-request](https://github.com/hwchase17/langchain/pull/5135) \\nto be validated.\", metadata={'source': 'README.md'})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "046e8904-74b9-4739-bd88-dd1a9c0ff4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "ename": "OutputParserException",
     "evalue": "Failed to parse Verbatims from completion  I don't know.. Got: Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/workspace.bda/langchain/libs/langchain/langchain/output_parsers/pydantic.py:27\u001b[0m, in \u001b[0;36mPydanticOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     26\u001b[0m     json_str \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mgroup()\n\u001b[0;32m---> 27\u001b[0m json_object \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpydantic_object\u001b[38;5;241m.\u001b[39mparse_obj(json_object)\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/__init__.py:359\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    358\u001b[0m     kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparse_constant\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m parse_constant\n\u001b[0;32m--> 359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 11\u001b[0m\n\u001b[1;32m      3\u001b[0m chain_type:Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstuff\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap_reduce\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap_rerank\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrefine\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap_reduce\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m qa_chain \u001b[38;5;241m=\u001b[39m RetrievalQAWithReferencesAndVerbatimsChain\u001b[38;5;241m.\u001b[39mfrom_chain_type(\n\u001b[1;32m      6\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[1;32m      7\u001b[0m     chain_type\u001b[38;5;241m=\u001b[39mchain_type,\n\u001b[1;32m      8\u001b[0m     retriever\u001b[38;5;241m=\u001b[39mretriever,\n\u001b[1;32m      9\u001b[0m     reduce_k_below_max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mqa_chain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFor the question \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, to answer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00manswer[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, the LLM use:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m answer[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_documents\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/workspace.bda/langchain/libs/langchain/langchain/chains/base.py:292\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    291\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 292\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    293\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    294\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    295\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    296\u001b[0m )\n",
      "File \u001b[0;32m~/workspace.bda/langchain/libs/langchain/langchain/chains/base.py:286\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    279\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    280\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    281\u001b[0m     inputs,\n\u001b[1;32m    282\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    285\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 286\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    289\u001b[0m     )\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    291\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/workspace.bda/langchain-qa_with_references/langchain_qa_with_references/chains/qa_with_references/base.py:241\u001b[0m, in \u001b[0;36mBaseQAWithReferencesChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    232\u001b[0m     doc\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_idx\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_idx_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    234\u001b[0m answers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcombine_documents_chain(\n\u001b[1;32m    235\u001b[0m     {\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcombine_documents_chain\u001b[38;5;241m.\u001b[39minput_key: docs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    239\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m_run_manager\u001b[38;5;241m.\u001b[39mget_child(),\n\u001b[1;32m    240\u001b[0m )\n\u001b[0;32m--> 241\u001b[0m answer, all_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43manswers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m selected_docs \u001b[38;5;241m=\u001b[39m [docs[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m all_idx \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(docs)]\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manswer_key: answer,\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_documents_key: selected_docs,\n\u001b[1;32m    247\u001b[0m }\n",
      "File \u001b[0;32m~/workspace.bda/langchain-qa_with_references/langchain_qa_with_references/chains/qa_with_references/base.py:200\u001b[0m, in \u001b[0;36mBaseQAWithReferencesChain._process_results\u001b[0;34m(self, answers, docs, run_manager)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m run_manager:\n\u001b[1;32m    199\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m run_manager:\n",
      "File \u001b[0;32m~/workspace.bda/langchain-qa_with_references/langchain_qa_with_references/chains/qa_with_references/base.py:187\u001b[0m, in \u001b[0;36mBaseQAWithReferencesChain._process_results\u001b[0;34m(self, answers, docs, run_manager)\u001b[0m\n\u001b[1;32m    183\u001b[0m         parser \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m    184\u001b[0m             Any, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcombine_documents_chain\n\u001b[1;32m    185\u001b[0m         )\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mprompt\u001b[38;5;241m.\u001b[39moutput_parser\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m parser\n\u001b[0;32m--> 187\u001b[0m references \u001b[38;5;241m=\u001b[39m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43manswer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m answer \u001b[38;5;241m=\u001b[39m references\u001b[38;5;241m.\u001b[39mresponse\n\u001b[1;32m    190\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_reference(answers, docs, references)\n",
      "File \u001b[0;32m~/workspace.bda/langchain/libs/langchain/langchain/output_parsers/pydantic.py:33\u001b[0m, in \u001b[0;36mPydanticOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     31\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpydantic_object\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m     32\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to parse \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from completion \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(msg, llm_output\u001b[38;5;241m=\u001b[39mtext)\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Failed to parse Verbatims from completion  I don't know.. Got: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "from langchain_qa_with_references.chains import RetrievalQAWithReferencesAndVerbatimsChain\n",
    "from typing import Literal\n",
    "chain_type:Literal[\"stuff\",\"map_reduce\",\"map_rerank\",\"refine\"]=\"map_reduce\"\n",
    "\n",
    "qa_chain = RetrievalQAWithReferencesAndVerbatimsChain.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=chain_type,\n",
    "    retriever=retriever,\n",
    "    reduce_k_below_max_tokens=True,\n",
    ")\n",
    "answer = qa_chain(\n",
    "    inputs={\n",
    "        \"question\": question,\n",
    "    }\n",
    ")\n",
    "print(f'For the question \"{question}\", to answer \"{answer[\"answer\"]}\", the LLM use:')\n",
    "for doc in answer[\"source_documents\"]:\n",
    "    print(f\"Source {doc.metadata['source']}\")\n",
    "    for verbatim in doc.metadata.get(\"verbatims\", []):\n",
    "        print(f'-  \"{verbatim}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563e5cc2-e02d-4c25-aa00-3d1440e33c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qa_with_reference",
   "language": "python",
   "name": "qa_with_reference"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
